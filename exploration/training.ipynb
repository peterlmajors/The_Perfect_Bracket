{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import (auc, classification_report, roc_auc_score, accuracy_score,\n",
    "#                              f1_score, log_loss, roc_curve, confusion_matrix,\n",
    "#                              precision_score, recall_score, plot_confusion_matrix,\n",
    "#                              make_scorer)\n",
    "\n",
    "# Import Data\n",
    "# X_train = pd.read_csv(\"../data/pipeline/X_train.csv\")\n",
    "# y_train = pd.read_csv(\"../data/pipeline/y_train.csv\")\n",
    "# X_test = pd.read_csv(\"../data/pipeline/X_test.csv\")\n",
    "# y_test = pd.read_csv(\"../data/pipeline/y_test.csv\")\n",
    "\n",
    "train = pd.read_csv(\"../data/pipeline/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM (build 21.0.1+12-29, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\Peter\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Peter\\AppData\\Local\\Temp\\tmp__26aims\n",
      "  JVM stdout: C:\\Users\\Peter\\AppData\\Local\\Temp\\tmp__26aims\\h2o_Peter_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Peter\\AppData\\Local\\Temp\\tmp__26aims\\h2o_Peter_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Peter_k7gun8</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.927 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.11 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.1\n",
       "H2O_cluster_version_age:    2 days\n",
       "H2O_cluster_name:           H2O_from_python_Peter_k7gun8\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.927 Gb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.11 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize H2O\n",
    "# h2o.init()\n",
    "# h2o.demo(\"glm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize H2O\n",
    "h2o.init()\n",
    "\n",
    "# Convert DataFrame to H2O Frame\n",
    "train_h2o = h2o.H2OFrame(train)\n",
    "\n",
    "# Test Train Split\n",
    "train_h2o['team1_win'] = train_h2o['team1_win'].asfactor()\n",
    "train_h2o, test = train_h2o.split_frame(ratios = [0.8], seed = 42)\n",
    "\n",
    "# Define the AutoML model\n",
    "aml = H2OAutoML(max_models = 10, seed = 42, nfolds = 5, balance_classes=True, stopping_metric='logloss')\n",
    "\n",
    "# Train the AutoML model with Feature and Target Columns\n",
    "aml.train(x = [col for col in train if any(substring in col for substring in ['diff', 'ratio', 'pythag'])], \n",
    "          y = 'team_win1', training_frame = train_h2o)\n",
    "\n",
    "# View leaderboard\n",
    "lb = aml.leaderboard\n",
    "print(lb)\n",
    "\n",
    "# Assign Best Model\n",
    "cbb_model = aml.leader\n",
    "\n",
    "# Shutdown H2O\n",
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign Model\n",
    "# model_t = XGBClassifier(n_estimators= 70, max_depth=4, eta = .05, subsample = .9, colsample_bytree = .8)\n",
    "#Utilize Cross Validation To Further Enhance Model\n",
    "# cv = RepeatedKFold(n_splits=10, n_repeats=8, random_state=1)\n",
    "# scores = cross_val_score(model_t, X_train, y_train, cv=cv, scoring = 'neg_log_loss', n_jobs = -1, error_score = 'raise')\n",
    "# scores = abs(scores)\n",
    "# print('Mean Log Loss: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build The Model\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", \n",
    "                              random_state = 42, \n",
    "                              eta = .04, \n",
    "                              max_depth = 6,\n",
    "                              min_child_weight = 3,\n",
    "                              n_estimators = 100,\n",
    "                              gamma = .6,\n",
    "                              reg_lambda = .2,\n",
    "                              subsample = 1,\n",
    "                              colsample_bytree = .99)\n",
    "\n",
    "#Fit The Model\n",
    "xgb_model.fit(X, Y, early_stopping_rounds = 5, eval_metric = 'logloss', eval_set = [(x, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update The Model Based On Cross Validation Tests and Fit and Balance Overfitting With Performance\n",
    "model_t = XGBClassifier(n_estimators= 40, max_depth = 4, eta = .05, subsample = .8, colsample_bytree = .9)\n",
    "print(\"                 Test Set                        Train Set\")\n",
    "model_t.fit(X_train, y_train, eval_set=[(X_test, y_test), (X_train, y_train)]) #Check For Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning\n",
    "param_grid = {'eta': [.0035],\n",
    "              'objective':['binary:logistic'],\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [1],\n",
    "              'n_estimators': [8],\n",
    "              'gamma': [.44],\n",
    "              'reg_lambda' : [.55],\n",
    "              'subsample': [1],\n",
    "              'colsample_bytree': [.5]}\n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "optimal_params = GridSearchCV(xgb_model, param_grid, n_jobs = 4, scoring = LogLoss, verbose = 0, cv = 3)\n",
    "\n",
    "optimal_params.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Score\n",
    "accuracy_score(test['team1_win'], test['prediction'])\n",
    "precision_score(test['team1_win'], test['prediction'])\n",
    "recall_score(test['team1_win'], test['prediction'])\n",
    "f1_score(test['team1_win'], test['prediction'])\n",
    "log_loss(test['team1_win'].values, test['prob'].values, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "feat_importances = pd.Series(xgb_model.feature_importances_, index= X.columns)\n",
    "feat_importances.nlargest(54).plot(kind='barh')\n",
    "sns.set(rc = {'figure.figsize':(14,14)})\n",
    "plt.title(\"Feature Importance of XGBoost Model\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examples\n",
    "FEATURES = [\n",
    "    #     \"WinPercentage\",\n",
    "    #     \"MedianScoreDiff\",\n",
    "    #     \"ChalkSeed\",\n",
    "    #     \"OppWinPercentage\",\n",
    "    #     \"OppMedianScoreDiff\",\n",
    "    #     \"OppChalkSeed\",\n",
    "    \"WinPctDiff\",\n",
    "    \"ChalkSeedDiff\",\n",
    "    #     \"538rating\",\n",
    "    #     \"538ratingOpp\",\n",
    "    \"538rating_diff\",\n",
    "]\n",
    "TARGET = \"Win\"\n",
    "\n",
    "\n",
    "X = df_historic_tourney_features[FEATURES]\n",
    "y = df_historic_tourney_features[TARGET]\n",
    "groups = df_historic_tourney_features[\"Season\"]\n",
    "seasons = df_historic_tourney_features[\"Season\"].unique()\n",
    "\n",
    "# Setup cross-validation\n",
    "gkf = GroupKFold(n_splits=df_historic_tourney_features[\"Season\"].nunique())\n",
    "cv_results = []\n",
    "models = []\n",
    "\n",
    "season_idx = 0\n",
    "for train_index, test_index in gkf.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Prepare the model\n",
    "    model = xgb.XGBRegressor(\n",
    "        eval_metric=\"logloss\",\n",
    "        n_estimators=1_000,\n",
    "        learning_rate=0.001,\n",
    "    )\n",
    "    holdout_season = seasons[season_idx]\n",
    "    print(f\"Holdout Season: {holdout_season}\")\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=100)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    score_ll = log_loss(y_test, y_pred)\n",
    "    y_pred = y_pred > 0.5\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_results.append(accuracy)\n",
    "    season_idx += 1\n",
    "    print(f\"Season {holdout_season}: {accuracy} {score_ll}\")\n",
    "    models.append(model)\n",
    "# Print the average accuracy across all folds\n",
    "print(\"Average CV Accuracy:\", np.mean(cv_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
