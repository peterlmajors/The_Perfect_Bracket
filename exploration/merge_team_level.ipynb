{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "# Import and Merge Historical Team Data \n",
    "mdcm = pd.read_csv('../data/mdcm/NCAA_Tourney_2002_2023.csv')\n",
    "team_spellings = pd.read_csv('../data/mdcm/team_spellings.csv')\n",
    "\n",
    "ncaa_sheets = pd.read_csv('../data/cbbdata/team/ncaa_sheets.csv').query('year != 2020')\n",
    "selection_sunday_resume = pd.read_csv('../data/cbbdata/team/selection_sunday_resume.csv').query('year != 2020')\n",
    "\n",
    "coach_results = pd.read_csv('../data/kaggle/march_madness_data/coach_results.csv')\n",
    "barttovik_home = pd.read_csv('../data/kaggle/march_madness_data/barttovik_home.csv')\n",
    "barttovik_away = pd.read_csv('../data/kaggle/march_madness_data/barttovik_away.csv')\n",
    "kenpom_barttovik = pd.read_csv('../data/kaggle/march_madness_data/kenpom_barttovik.csv')\n",
    "shooting_splits = pd.read_csv('../data/kaggle/march_madness_data/shooting_splits.csv')\n",
    "heat_check = pd.read_csv('../data/kaggle/march_madness_data/heat_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDCM and NCAA Sheets (2019-2024) -----------------------\n",
      "\n",
      "Team 1 Merge ...\n",
      "\n",
      "Original Team 1 Merge: 268 total rows.\n",
      "Matched During Iteration: 214\n",
      "Unmatched Rows Remaining: 54 \n",
      "\n",
      "Correcting Team 1 Merge ...\n",
      "\n",
      "Team 1 Season Loop 1: 54 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 54 \n",
      "\n",
      "Team 1 Season Loop 2: 54 total rows.\n",
      "Matched During Iteration: 9\n",
      "Unmatched Rows Remaining: 45 \n",
      "\n",
      "Team 1 Season Loop 3: 45 total rows.\n",
      "Matched During Iteration: 31\n",
      "Unmatched Rows Remaining: 14 \n",
      "\n",
      "Team 1 Season Loop 4: 14 total rows.\n",
      "Matched During Iteration: 6\n",
      "Unmatched Rows Remaining: 8 \n",
      "\n",
      "Team 1 Season Loop 5: 8 total rows.\n",
      "Matched During Iteration: 3\n",
      "Unmatched Rows Remaining: 5 \n",
      "\n",
      "Team 1 Season Loop 6: 5 total rows.\n",
      "Matched During Iteration: 3\n",
      "Unmatched Rows Remaining: 2 \n",
      "\n",
      "Team 1 Season Loop 7: 2 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 2 \n",
      "\n",
      "Team 1 Season Loop 8: 2 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 2 \n",
      "\n",
      "Team 1 Season Loop 9: 2 total rows.\n",
      "Matched During Iteration: 2\n",
      "Unmatched Rows Remaining: 0 \n",
      "\n",
      "Success! Team 1 Merge Completed Early!\n",
      "\n",
      "Team 2 Merge ...\n",
      "\n",
      "Original Team 2 Merge: 268 total rows.\n",
      "Matched During Iteration: 184\n",
      "Unmatched Rows Remaining: 84 \n",
      "\n",
      "Correcting Team 2 Merge ...\n",
      "\n",
      "Team 2 Season Loop 1: 84 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 84 \n",
      "\n",
      "Team 2 Season Loop 2: 84 total rows.\n",
      "Matched During Iteration: 14\n",
      "Unmatched Rows Remaining: 70 \n",
      "\n",
      "Team 2 Season Loop 3: 70 total rows.\n",
      "Matched During Iteration: 46\n",
      "Unmatched Rows Remaining: 24 \n",
      "\n",
      "Team 2 Season Loop 4: 24 total rows.\n",
      "Matched During Iteration: 13\n",
      "Unmatched Rows Remaining: 11 \n",
      "\n",
      "Team 2 Season Loop 5: 11 total rows.\n",
      "Matched During Iteration: 6\n",
      "Unmatched Rows Remaining: 5 \n",
      "\n",
      "Team 2 Season Loop 6: 5 total rows.\n",
      "Matched During Iteration: 2\n",
      "Unmatched Rows Remaining: 3 \n",
      "\n",
      "Team 2 Season Loop 7: 3 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 3 \n",
      "\n",
      "Team 2 Season Loop 8: 3 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 3 \n",
      "\n",
      "Team 2 Season Loop 9: 3 total rows.\n",
      "Matched During Iteration: 3\n",
      "Unmatched Rows Remaining: 0 \n",
      "\n",
      "Success! Team 2 Merge Completed Early!\n",
      "\n",
      "Filter Views of Resulting DataFrame -------------------------\n",
      "\n",
      "Team1:\n",
      "Great! No Null Rows Post 2019\n",
      "Great! No Matched Rows Pre 2019\n",
      "\n",
      "Team2:\n",
      "Great! No Null Rows Post 2019\n",
      "Great! No Matched Rows Pre 2019\n",
      "\n",
      "MDCM and Selection Sunday (2008 - 2024) -----------------------\n",
      "\n",
      "Team 1 Merge ...\n",
      "\n",
      "Original Team 1 Merge: 998 total rows.\n",
      "Matched During Iteration: 784\n",
      "Unmatched Rows Remaining: 214 \n",
      "\n",
      "Correcting Team 1 Merge ...\n",
      "\n",
      "Team 1 Season Loop 1: 214 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 214 \n",
      "\n",
      "Team 1 Season Loop 2: 214 total rows.\n",
      "Matched During Iteration: 9\n",
      "Unmatched Rows Remaining: 205 \n",
      "\n",
      "Team 1 Season Loop 3: 205 total rows.\n",
      "Matched During Iteration: 101\n",
      "Unmatched Rows Remaining: 104 \n",
      "\n",
      "Team 1 Season Loop 4: 104 total rows.\n",
      "Matched During Iteration: 37\n",
      "Unmatched Rows Remaining: 67 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Temp\\ipykernel_20636\\2199748203.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'team{team_num}_teamname'] = df[f'team{team_num}_teamname'].str.lower()\n",
      "C:\\Users\\Peter\\AppData\\Local\\Temp\\ipykernel_20636\\2199748203.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'team{team_num}_teamname'] = df[f'team{team_num}_teamname'].str.lower()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team 1 Season Loop 5: 67 total rows.\n",
      "Matched During Iteration: 6\n",
      "Unmatched Rows Remaining: 61 \n",
      "\n",
      "Team 1 Season Loop 6: 61 total rows.\n",
      "Matched During Iteration: 2\n",
      "Unmatched Rows Remaining: 59 \n",
      "\n",
      "Team 1 Season Loop 7: 59 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 59 \n",
      "\n",
      "Team 1 Season Loop 8: 59 total rows.\n",
      "Matched During Iteration: 1\n",
      "Unmatched Rows Remaining: 58 \n",
      "\n",
      "Team 1 Season Loop 9: 58 total rows.\n",
      "Matched During Iteration: 6\n",
      "Unmatched Rows Remaining: 52 \n",
      "\n",
      "Team 1 Season Loop 10: 52 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 52 \n",
      "\n",
      "Team 1 Season Loop 11: 52 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 52 \n",
      "\n",
      "Team 2 Merge ...\n",
      "\n",
      "Original Team 2 Merge: 998 total rows.\n",
      "Matched During Iteration: 609\n",
      "Unmatched Rows Remaining: 389 \n",
      "\n",
      "Correcting Team 2 Merge ...\n",
      "\n",
      "Team 2 Season Loop 1: 389 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 389 \n",
      "\n",
      "Team 2 Season Loop 2: 389 total rows.\n",
      "Matched During Iteration: 21\n",
      "Unmatched Rows Remaining: 368 \n",
      "\n",
      "Team 2 Season Loop 3: 368 total rows.\n",
      "Matched During Iteration: 112\n",
      "Unmatched Rows Remaining: 256 \n",
      "\n",
      "Team 2 Season Loop 4: 256 total rows.\n",
      "Matched During Iteration: 37\n",
      "Unmatched Rows Remaining: 219 \n",
      "\n",
      "Team 2 Season Loop 5: 219 total rows.\n",
      "Matched During Iteration: 8\n",
      "Unmatched Rows Remaining: 211 \n",
      "\n",
      "Team 2 Season Loop 6: 211 total rows.\n",
      "Matched During Iteration: 5\n",
      "Unmatched Rows Remaining: 206 \n",
      "\n",
      "Team 2 Season Loop 7: 206 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 206 \n",
      "\n",
      "Team 2 Season Loop 8: 206 total rows.\n",
      "Matched During Iteration: 3\n",
      "Unmatched Rows Remaining: 203 \n",
      "\n",
      "Team 2 Season Loop 9: 203 total rows.\n",
      "Matched During Iteration: 8\n",
      "Unmatched Rows Remaining: 195 \n",
      "\n",
      "Team 2 Season Loop 10: 195 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 195 \n",
      "\n",
      "Team 2 Season Loop 11: 195 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 195 \n",
      "\n",
      "Filter Views of Resulting DataFrame -------------------------\n",
      "\n",
      "Team1:\n",
      "Great! No Null Rows Post 2008\n",
      "Great! No Matched Rows Pre 2008\n",
      "\n",
      "Team2:\n",
      "Oh No! There were 790 matches and 168 post 2008 null games.\n",
      "Despite all the mismatches, none of them were in the merged onto Dataframe.\n",
      "Great! No Matched Rows Pre 2008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Functions\n",
    "def merge_team_season(df: pd.DataFrame, df_merge_onto: pd.DataFrame, filter_df_merge_onto_year_cutoff: bool = False, filter_df_merge_onto_year = None, title: str = None, home_away: str = None):\n",
    "    \"\"\"\n",
    "    \n",
    "        Function to merge teams and their seasons in college basketball with a bevy of alternative spellings, using team_spellings.csv.\n",
    "    \n",
    "        df (pd.DataFrame): The dataframe you'd like to establish as your left, or original df. Must contain 'teamname' and 'season' columns.\n",
    "        \n",
    "        df_merge_onto (pd.DataFrame): The dataframe you'd like to left merge onto df. Must contain 'team' and 'year' columns.\n",
    "        \n",
    "        filter_df_merge_onto_year_cutoff (bool): A boolean determining if there is a cutoff year for the anchor data (i.e. Statcast data only \n",
    "                                                reaching back to 2015). This does not affect the merge, just the reporting success messages.\n",
    "        \n",
    "        filter_df_merge_onto_year (int): If there is a cutoff year for the df_merge_onto, the year of interest. This does not affect the \n",
    "                                        merge, just the reporting success messages.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Print Title of Run For Terminal\n",
    "    if title:\n",
    "        print(title,'-----------------------\\n')\n",
    "        \n",
    "    # If Oncoming Data Filtered By Specifc Year \n",
    "    if filter_df_merge_onto_year_cutoff == True:\n",
    "        df_post_cutoff = df[df['season'] >= filter_df_merge_onto_year]\n",
    "        df_pre_cutoff = df[df['season'] < filter_df_merge_onto_year]\n",
    "        df = df_post_cutoff\n",
    "    \n",
    "    # Find Null df Column Identifier For Oncoming DF\n",
    "    for col_name in df_merge_onto.columns:\n",
    "        if 'team' not in col_name.lower() and 'year' not in col_name.lower():\n",
    "            col_null_match_identifier = col_name\n",
    "            break\n",
    "    \n",
    "    # Set Both Teamname Columns To Lowercas\n",
    "    for team_num in range(1,3):\n",
    "        df[f'team{team_num}_teamname'] = df[f'team{team_num}_teamname'].str.lower()\n",
    "    \n",
    "    # Loop Through Team 1 and Team 2\n",
    "    df_both_teams = pd.DataFrame()\n",
    "    for team_num in range(1, 3):\n",
    "        \n",
    "        # Adjust Column Names Due To Team1 and Team2\n",
    "        df_merge_onto.columns = df_merge_onto.columns.str[6:] if team_num == 2 else df_merge_onto.columns\n",
    "        df_merge_onto = df_merge_onto.add_prefix(f'team{team_num}_')\n",
    "        \n",
    "        # Set The Team Column To Lowercase\n",
    "        df_merge_onto[f'team{team_num}_team'] = df_merge_onto[f'team{team_num}_team'].str.lower()\n",
    "        \n",
    "        # If Second Iteration, Find The Merge Columns and The Spellings Ones To Keep\n",
    "        if team_num == 2:\n",
    "            spellings = ['team2_teamname', 'season']\n",
    "            for col in df.columns:\n",
    "                if f\"team{team_num}_name_spelling\" in col: \n",
    "                    spellings.append(col)\n",
    "            df = df[spellings]\n",
    "        \n",
    "         # Original Merge\n",
    "        print(f\"Team {team_num} Merge ...\\n\")\n",
    "        \n",
    "        df_merged = pd.merge(df, df_merge_onto, how = 'left', left_on = [f'team{team_num}_teamname', 'season'], right_on = [f'team{team_num}_team', f'team{team_num}_year'])\n",
    "        \n",
    "        # Split Up Merged and Unmerged Data\n",
    "        df_not_merged = df_merged[df_merged[f'team{team_num}_{col_null_match_identifier}'].isna() == True]\n",
    "        df_merged = df_merged[df_merged[f'team{team_num}_{col_null_match_identifier}'].isna() == False]\n",
    "        \n",
    "        print(f'Original Team {team_num} Merge:', len(df), 'total rows.')\n",
    "        print('Matched During Iteration:', len(df_merged)) \n",
    "        print('Unmatched Rows Remaining:', len(df_not_merged), '\\n') \n",
    "        \n",
    "        # Remove Columns That Didn't Merge Properly Based On Num of Columns\n",
    "        neg_col_count_df_merge_onto = df_merge_onto.shape[1] * -1\n",
    "        df_not_merged = df_not_merged.iloc[:, :neg_col_count_df_merge_onto]\n",
    "          \n",
    "        # Loop Through Columnns To Fix The Merge\n",
    "        print(f\"Correcting Team {team_num} Merge ...\\n\")\n",
    "        merge_complete, i = False, 1\n",
    "        while merge_complete == False:\n",
    "            \n",
    "            # Perform Loop Everytime More Unmatched Columns Are Found\n",
    "            team_season_loop = pd.merge(df_not_merged, df_merge_onto, how = 'left', left_on = [f'team{team_num}_name_spelling_{i}', 'season'], right_on = [f'team{team_num}_team', f'team{team_num}_year'])\n",
    "            print(f'Team {team_num} Season Loop {i}:', len(team_season_loop), 'total rows.')\n",
    "            \n",
    "            # Split Up The Matched and Unmatched\n",
    "            matched_df = team_season_loop[team_season_loop[f'team{team_num}_{col_null_match_identifier}'].isna() == False]\n",
    "            print('Matched During Iteration:', len(matched_df)) \n",
    "            unmatched_df = team_season_loop[team_season_loop[f'team{team_num}_{col_null_match_identifier}'].isna() == True]\n",
    "            print('Unmatched Rows Remaining:', len(unmatched_df), '\\n') \n",
    "            \n",
    "            # For The DataFrames With Data In The Column From Second DF, Add To team_season\n",
    "            if len(matched_df) > 0:\n",
    "                df_merged = pd.concat([df_merged, matched_df])\n",
    "            # If There Are Still Null Rows, Throw Those Back In The Loop For The Next Iteration\n",
    "            if len(unmatched_df) > 0:\n",
    "                df_not_merged = unmatched_df.iloc[:, :neg_col_count_df_merge_onto]\n",
    "            # If There Aren't Any Null Rows Left, End The Loop\n",
    "            else:\n",
    "                print(f'Success! Team {team_num} Merge Completed Early!\\n')\n",
    "                merge_complete = True\n",
    "            if i == 11:\n",
    "                merge_complete = True \n",
    "            i += 1\n",
    "   \n",
    "        # Concat Team 1 or 2 Onto Full DataFrame\n",
    "        if team_num == 2:\n",
    "            spellings = []\n",
    "            for col in df_merged.columns:\n",
    "                if 'team2_name_spelling' not in col:\n",
    "                    spellings.append(col)\n",
    "                \n",
    "            df_both_teams = pd.merge(df_both_teams, df_merged[spellings], how = 'left', on = [f'team2_teamname', 'season'])\n",
    "        else:\n",
    "            df_both_teams = df_merged\n",
    "    \n",
    "    # Inspect Final Results\n",
    "    print(\"Filter Views of Resulting DataFrame -------------------------\\n\")\n",
    "    for team_num in range(1, 3):\n",
    "        print(f'Team{team_num}:')\n",
    "        if filter_df_merge_onto_year_cutoff == True:\n",
    "            # Gather Data About Merge Post Cutoff\n",
    "            post_cutoff_rows = df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == False) & (df_both_teams['season'] >= filter_df_merge_onto_year)].shape[0]\n",
    "            post_cutoff_rows_na = df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == True) & (df_both_teams['season'] >= filter_df_merge_onto_year)].shape[0]\n",
    "            if post_cutoff_rows_na > 0:\n",
    "                print(f'Oh No! There were {post_cutoff_rows} matches and {post_cutoff_rows_na} post {filter_df_merge_onto_year} null games.')\n",
    "                # Get Teamnames That Dont Merge\n",
    "                if pd.read_csv('../data/sample_spell.csv').shape[0] == pd.merge(pd.read_csv('../data/mdcm/team_spellings.csv'), \n",
    "                    pd.read_csv('../data/sample_spell.csv'), how = 'inner', left_on = 'name_spelling', right_on = 'team2_teamname').shape[0]:\n",
    "                        print(\"Despite all the mismatches, none of them were in the merged onto Dataframe.\")\n",
    "                else:\n",
    "                    print(\"Here are the distinct team names from the 'df' dataframe that weren't merged properly:\")\n",
    "                    print(df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == True) & (df_both_teams['season'] >= filter_df_merge_onto_year)][f'team{team_num}_teamname'].drop_duplicates().sort_values())\n",
    "            else:\n",
    "                print(f'Great! No Null Rows Post {filter_df_merge_onto_year}')\n",
    "     \n",
    "            # Gather Data About Merge Pre Cutoff\n",
    "            pre_cutoff_rows = df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == False) & (df_both_teams['season'] < filter_df_merge_onto_year)].shape[0]\n",
    "            if pre_cutoff_rows == 0:\n",
    "                print(f'Great! No Matched Rows Pre {filter_df_merge_onto_year}\\n')\n",
    "                                \n",
    "    # Concat Pre and Post Cutoff If Exists\n",
    "    if filter_df_merge_onto_year_cutoff == True:\n",
    "        df_both_teams = pd.concat([df_both_teams, df_pre_cutoff], ignore_index=True)    \n",
    "    \n",
    "    return df_both_teams.drop(['team1_team','team1_year', 'team2_team', 'team2_year'], axis = 1)\n",
    "\n",
    "# Adjust Team Spellings\n",
    "team_spellings = team_spellings.pivot_table(index='team_id', columns=team_spellings.groupby('team_id').cumcount(), values='name_spelling', aggfunc='first')\n",
    "team_spellings.columns = [f'name_spelling_{i + 1}' for i in range(team_spellings.shape[1])]\n",
    "team_spellings.reset_index(inplace=True)\n",
    "\n",
    "# Merge Team Spellings\n",
    "team_spellings_t1 = team_spellings.add_prefix('team1_')\n",
    "mdcm = pd.merge(mdcm, team_spellings_t1, how = 'inner', left_on = ['team1_id'], right_on = ['team1_team_id'])\n",
    "team_spellings_t2 = team_spellings.add_prefix('team2_')\n",
    "mdcm = pd.merge(mdcm, team_spellings_t2, how = 'inner', left_on = ['team2_id'], right_on = ['team2_team_id'])\n",
    "\n",
    "# Merge MDCM and NCAA_Sheets (2019-2024)\n",
    "ncaa_sheets.drop(['seed', 'net', 'quad_1a', 'quad_1', 'quad_2', 'quad_1_and_2', 'quad_3', 'quad_4'], axis = 1, inplace = True)\n",
    "mdcm = merge_team_season(mdcm, ncaa_sheets, filter_df_merge_onto_year_cutoff = True, filter_df_merge_onto_year = 2019, title = 'MDCM and NCAA Sheets (2019-2024)')\n",
    "\n",
    "# Merge MDCM and Selection Sunday (2008-2024)\n",
    "selection_sunday_resume = selection_sunday_resume[selection_sunday_resume['year'] != 'Year']\n",
    "selection_sunday_resume['year'] = selection_sunday_resume['year'].astype(int)\n",
    "selection_sunday_resume.drop(columns = ['net', 'seed'], axis = 1, inplace = True)\n",
    "selection_sunday_resume.rename(columns={'score': 'team_score'}, inplace=True)\n",
    "mdcm = merge_team_season(mdcm, selection_sunday_resume, filter_df_merge_onto_year_cutoff = True, filter_df_merge_onto_year = 2008, title = 'MDCM and Selection Sunday (2008 - 2024)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barttovik_home\n",
      "   home_year  home_team no  home_team id        home_team  home_badj em  \\\n",
      "0       2024          1079             2            Akron           8.8   \n",
      "1       2024          1078             3          Alabama          32.4   \n",
      "2       2024          1077             7  Appalachian St.          14.1   \n",
      "3       2024          1076             8          Arizona          31.3   \n",
      "4       2024          1075            12           Auburn          29.4   \n",
      "\n",
      "   home_badj o  home_badj d  home_barthag  home_games  home_w  home_l  \\\n",
      "0        107.6         98.8         0.727          10      10       0   \n",
      "1        128.1         95.7         0.966          14      13       1   \n",
      "2        110.5         96.4         0.828          13      13       0   \n",
      "3        120.8         89.5         0.969          15      14       1   \n",
      "4        118.9         89.5         0.963          14      13       1   \n",
      "\n",
      "   home_win%  home_efg%  home_efg%d  home_ftr  home_ftrd  home_tov%  \\\n",
      "0  100.00000       53.1        46.9      36.2       25.8       14.9   \n",
      "1   92.85714       59.3        45.6      34.3       32.4       15.6   \n",
      "2  100.00000       54.9        44.0      37.7       18.5       14.6   \n",
      "3   93.33333       57.7        45.4      35.8       20.7       15.9   \n",
      "4   92.85714       52.9        41.4      45.6       39.5       14.5   \n",
      "\n",
      "   home_tov%d  home_oreb%  home_dreb%  home_op oreb%  home_op dreb%  \\\n",
      "0        18.0        29.3        75.0           25.0           70.7   \n",
      "1        17.2        37.4        70.6           29.4           62.6   \n",
      "2        14.4        28.8        70.8           29.2           71.2   \n",
      "3        19.1        38.2        80.7           19.3           61.8   \n",
      "4        20.5        34.4        69.6           30.4           65.6   \n",
      "\n",
      "   home_raw t  home_2pt%  home_2pt%d  home_3pt%  home_3pt%d  home_blk%  \\\n",
      "0        66.8       54.0        48.6       34.5        29.3       10.1   \n",
      "1        73.3       57.2        47.5       41.1        28.2       11.6   \n",
      "2        69.1       54.5        42.8       37.1        31.1       15.2   \n",
      "3        75.4       57.2        43.5       39.2        32.2       11.6   \n",
      "4        71.5       54.7        40.1       33.4        29.2       17.3   \n",
      "\n",
      "   home_blked%  home_ast%  home_op ast%  home_2ptr  home_3ptr  home_2ptrd  \\\n",
      "0          7.2       51.5          41.4       60.2       39.8        62.5   \n",
      "1         11.3       54.7          39.1       52.1       47.9        61.8   \n",
      "2          5.5       47.9          37.6       69.2       30.8        69.5   \n",
      "3          6.4       62.7          56.4       66.6       33.4        59.6   \n",
      "4          8.6       64.8          41.5       60.8       39.2        65.7   \n",
      "\n",
      "   home_3ptrd  home_badj t  home_avg hgt  home_eff hgt  home_exp  home_talent  \\\n",
      "0        37.5         66.6        76.729        79.949     2.587       10.725   \n",
      "1        38.2         73.3        78.230        82.473     2.077       26.428   \n",
      "2        30.5         68.2        76.916        80.705     2.144       17.120   \n",
      "3        40.4         74.5        78.051        81.447     1.955       70.662   \n",
      "4        34.3         71.6        77.661        80.947     2.202       43.205   \n",
      "\n",
      "   home_ft%  home_op ft%  home_pppo  home_pppd  home_elite sos  \\\n",
      "0      73.6         64.9      1.129      0.936           5.345   \n",
      "1      79.6         66.1      1.291      0.969          18.701   \n",
      "2      71.7         63.0      1.149      0.951           8.517   \n",
      "3      72.0         65.5      1.231      0.866          14.061   \n",
      "4      78.1         75.9      1.186      0.910          14.876   \n",
      "\n",
      "   home_badj em rank  home_badj o rank  home_badj d rank  home_barthag rank  \\\n",
      "0                104               148                75                104   \n",
      "1                  3                 2                33                  7   \n",
      "2                 60               103                45                 60   \n",
      "3                  7                12                 9                  6   \n",
      "4                  8                23                 9                  8   \n",
      "\n",
      "   home_efg% rank  home_efgd% rank  home_ftr rank  home_ftrd rank  \\\n",
      "0             131               99            159              68   \n",
      "1               9               43            208             228   \n",
      "2              76               18            126               5   \n",
      "3              25               37            166              11   \n",
      "4             144                4             26             328   \n",
      "\n",
      "   home_tov% rank  home_tov%d rank  home_oreb% rank  home_dreb% rank  \\\n",
      "0              97              160              184               63   \n",
      "1             136              203               19              221   \n",
      "2              85              334              205              211   \n",
      "3             148              109               14                2   \n",
      "4              80               57               48              270   \n",
      "\n",
      "   home_op oreb% rank  home_op dreb% rank  home_raw t rank  home_2pt% rank  \\\n",
      "0                  63                 184              275             108   \n",
      "1                 221                  19               15              33   \n",
      "2                 211                 205              154              98   \n",
      "3                   2                  14                3              33   \n",
      "4                 270                  48               48              93   \n",
      "\n",
      "   home_2pt%d rank  home_3pt% rank  home_3pt%d rank  home_blk% rank  \\\n",
      "0              167             192               48             173   \n",
      "1              129              16               25             106   \n",
      "2               17              79              117              21   \n",
      "3               26              31              159             106   \n",
      "4                3             238               46               7   \n",
      "\n",
      "   home_blked% rank  home_ast% rank  home_op ast% rank  home_2ptr rank  \\\n",
      "0               123             193                 70             238   \n",
      "1               331             138                 37             350   \n",
      "2                26             267                 21              43   \n",
      "3                67              33                323              86   \n",
      "4               211              23                 72             222   \n",
      "\n",
      "   home_3ptr rank  home_2ptrd rank  home_3ptrd rank  home_badjt rank  \\\n",
      "0             127              161              205              288   \n",
      "1              13              141              226               15   \n",
      "2             322              337               27              200   \n",
      "3             279               81              284                5   \n",
      "4             143              261              107               44   \n",
      "\n",
      "   home_avg hgt rank  home_eff hgt rank  home_exp rank  home_talent rank  \\\n",
      "0                247                199             19               177   \n",
      "1                 34                  8            160               110   \n",
      "2                214                102            140               143   \n",
      "3                 49                 37            198                11   \n",
      "4                 92                 78            124                65   \n",
      "\n",
      "   home_ft% rank  home_op ft% rank  home_pppo rank  home_pppd rank  \\\n",
      "0            141                16             104              37   \n",
      "1             14                25               1              91   \n",
      "2            213                 6              77              55   \n",
      "3            197                19              12               6   \n",
      "4             33               328              36              18   \n",
      "\n",
      "   home_elite sos rank  \n",
      "0                  190  \n",
      "1                   14  \n",
      "2                  118  \n",
      "3                   62  \n",
      "4                   50  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Temp\\ipykernel_20636\\2199748203.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'team{team_num}_teamname'] = df[f'team{team_num}_teamname'].str.lower()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'team1_team'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'team1_team'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [174]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{col: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m85\u001b[39m:]}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m---> 16\u001b[0m         mdcm \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_team_season\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdcm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_df_merge_onto_year_cutoff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mfilter_df_merge_onto_year\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2008\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhome_away\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# elif file in files[:-2]:\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m#     print(file)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m mdcm\u001b[38;5;241m.\u001b[39mhead()\n",
      "Input \u001b[1;32mIn [173]\u001b[0m, in \u001b[0;36mmerge_team_season\u001b[1;34m(df, df_merge_onto, filter_df_merge_onto_year_cutoff, filter_df_merge_onto_year, title, home_away)\u001b[0m\n\u001b[0;32m     44\u001b[0m df_merge_onto \u001b[38;5;241m=\u001b[39m df_merge_onto\u001b[38;5;241m.\u001b[39madd_prefix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Set The Team Column To Lowercase\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m df_merge_onto[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_team\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_merge_onto\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mteam_num\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_team\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# If Second Iteration, Find The Merge Columns and The Spellings Ones To Keep\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m team_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'team1_team'"
     ]
    }
   ],
   "source": [
    "# Merge Kaggle march_madness_data\n",
    "files = ['coach_results', 'barttovik_home', 'barttovik_away', 'kenpom_barttovik', 'shooting_splits', 'heat_check']\n",
    "for file in files:\n",
    "    df = pd.read_csv(f'../data/kaggle/march_madness_data/{file}.csv')\n",
    "    \n",
    "    # if file == 'coach_results':\n",
    "    #     print(file)\n",
    "        # need additional param for coach id\n",
    "        \n",
    "    if file in files[1:3]:\n",
    "        print(file)\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df.drop(columns = ['seed', 'round', 'wab'], axis = 1, inplace = True)\n",
    "        df.rename(columns={col: f'{file[-4:]}_' + col for col in df.columns[-85:]}, inplace=True)\n",
    "        print(df.head())\n",
    "        mdcm = merge_team_season(mdcm, df, filter_df_merge_onto_year_cutoff = True,  filter_df_merge_onto_year = 2008, home_away = file[-4:])\n",
    "        \n",
    "    # elif file in files[:-2]:\n",
    "    #     print(file)\n",
    "    \n",
    "mdcm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Team Ratings By Day (2015-2019)\n",
    "team_ratings = pd.read_csv('../data/cbbdata/team/team_ratings.csv').query('year != 2020')\n",
    "team_ratings['date']= pd.to_datetime(team_ratings['date'])\n",
    "\n",
    "# Split Daily Team Ranknings By Before/After Selection Sunday\n",
    "ss_dict = {2024: \"2024-3-17\", 2023: \"2023-3-12\", 2022: \"2022-3-13\", \n",
    "           2021: \"2021-3-14\", 2019: \"2019-3-17\", 2018: \"2018-3-11\", \n",
    "           2017: \"2017-3-12\", 2016: \"2016-3-13\", 2015: \"2015-3-15\"}\n",
    "\n",
    "# Create A Pre and During NCAA Tournament Day By Day Ratings\n",
    "team_rating_pre_ncaa = pd.DataFrame(columns = team_ratings.columns)\n",
    "team_rating_ncaa = pd.DataFrame(columns = team_ratings.columns)\n",
    "for year, ss_date in ss_dict.items():\n",
    "    team_rating_pre_ncaa = pd.concat([team_rating_pre_ncaa, team_ratings[(team_ratings['year'] == year) & (team_ratings['date'] < ss_date)]])    \n",
    "    team_rating_ncaa = pd.concat([team_rating_ncaa, team_ratings[(team_ratings['year'] == year) & (team_ratings['date'] > ss_date)]])\n",
    "    \n",
    "# Look At Team Rating By Day and Calculate Rolling Adj Offensive Rank\n",
    "team_rating_pre_ncaa['rolling_avg_adj_o_rk'] = team_rating_pre_ncaa.groupby(['team', 'year'])['adj_o'].transform(lambda x: x.rolling(window=3).mean())\n",
    "df = team_rating_pre_ncaa[(team_rating_pre_ncaa['team'] == 'Kentucky') & (team_rating_pre_ncaa['year'] == 2015)]\n",
    "# team_rating_ncaa['rolling_avg_adj_o_rk'] = team_rating_ncaa.groupby(['team', 'year'])['adj_o'].transform(lambda x: x.rolling(window=3).mean())\n",
    "# df = team_rating_ncaa[(team_rating_ncaa['team'] == 'Kentucky') & (team_rating_ncaa['year'] == 2015)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
