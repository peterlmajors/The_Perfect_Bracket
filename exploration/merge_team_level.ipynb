{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production (Importing, Functions, Team Spelling, Merging, Exporting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Data\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "# MDCM\n",
    "mdcm = pd.read_csv('../data/mdcm/NCAA_Tourney_2002_2023.csv')\n",
    "team_spellings = pd.read_csv('../data/mdcm/team_spellings.csv')\n",
    "\n",
    "# March Machine Learning Mania 2024\n",
    "\n",
    "# CBBData\n",
    "selection_sunday_resume = pd.read_csv('../data/cbbdata/team/selection_sunday_resume.csv').query('year != 2020')\n",
    "\n",
    "# Kaggle\n",
    "coach_results = pd.read_csv('../data/kaggle/march_madness_data/coach_results.csv')\n",
    "barttovik_home = pd.read_csv('../data/kaggle/march_madness_data/barttovik_home.csv')\n",
    "barttovik_away = pd.read_csv('../data/kaggle/march_madness_data/barttovik_away.csv')\n",
    "kenpom_barttovik = pd.read_csv('../data/kaggle/march_madness_data/kenpom_barttovik.csv')\n",
    "shooting_splits = pd.read_csv('../data/kaggle/march_madness_data/shooting_splits.csv')\n",
    "heat_check = pd.read_csv('../data/kaggle/march_madness_data/heat_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "def merge_team_season(df: pd.DataFrame, df_merge_onto: pd.DataFrame, filter_df_merge_onto_year = None, title: str = None):\n",
    "    \"\"\"\n",
    "    \n",
    "        Function to merge teams and their seasons in college basketball with a bevy of alternative spellings, using team_spellings.csv.\n",
    "    \n",
    "        df (pd.DataFrame): The dataframe you'd like to establish as your left, or original df. Must contain 'teamname' and 'season' columns.\n",
    "        \n",
    "        df_merge_onto (pd.DataFrame): The dataframe you'd like to left merge onto df. Must contain 'team' and 'year' columns.\n",
    "        \n",
    "        filter_df_merge_onto_year (int): If there is a cutoff year for the df_merge_onto, the year of interest. This does not affect the \n",
    "                                        merge, just the reporting success messages.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Print Title of Run For Terminal\n",
    "    if title:\n",
    "        print(title,'-----------------------\\n')\n",
    "        \n",
    "    # If Oncoming Data Filtered By Specifc Year \n",
    "    if filter_df_merge_onto_year != None:\n",
    "        df_post_cutoff = df[df['season'] >= filter_df_merge_onto_year]\n",
    "        df_pre_cutoff = df[df['season'] < filter_df_merge_onto_year]\n",
    "        df = df_post_cutoff\n",
    "    \n",
    "    # Find Null df Column Identifier For Oncoming DF\n",
    "    for col_name in df_merge_onto.columns:\n",
    "        if 'team' not in col_name.lower() and 'year' not in col_name.lower():\n",
    "            col_null_match_identifier = col_name\n",
    "            print('Column Null Match Identifier:', col_null_match_identifier,'\\n')\n",
    "            break\n",
    "     \n",
    "    # Set Both Teamname Columns To Lowercase Easier Merging\n",
    "    for team_num in range(1,3):\n",
    "        df[f'team{team_num}_teamname'] = df[f'team{team_num}_teamname'].str.lower()\n",
    "    \n",
    "    # Loop Through Team 1 and Team 2\n",
    "    df_both_teams = pd.DataFrame()\n",
    "    for team_num in range(1, 3):\n",
    "        \n",
    "        # Adjust Column Names Due To Team1 and Team2 (Remove 'team1_' or 'team1_'/'team2_')\n",
    "        if team_num == 2:\n",
    "            df_merge_onto.columns = df_merge_onto.columns.str[6:]\n",
    "        df_merge_onto = df_merge_onto.add_prefix(f'team{team_num}_')\n",
    "        \n",
    "        # Establish df_merge_onto Team Column Name and Set to Lowercase\n",
    "        df_merge_onto[f'team{team_num}_team'] = df_merge_onto[f'team{team_num}_team'].str.lower()\n",
    "        \n",
    "        # If Second Iteration, Find The Merge Columns and The Spellings Ones To Keep\n",
    "        if team_num == 2:\n",
    "            spellings = ['team2_teamname', 'season']\n",
    "            for col in df.columns:\n",
    "                if f\"team{team_num}_name_spelling\" in col: \n",
    "                    spellings.append(col)\n",
    "            df = df[spellings].drop_duplicates()\n",
    "            \n",
    "        # Original Merge For Team 1 or 2\n",
    "        print(f\"Team {team_num} Merge ...\\n\")\n",
    "        df_merged = pd.merge(df, df_merge_onto, how = 'left', left_on = [f'team{team_num}_teamname', 'season'], right_on = [f'team{team_num}_team', f'team{team_num}_year'])\n",
    "        \n",
    "        # Original Split Up Merged and Unmerged Data\n",
    "        df_not_merged = df_merged[df_merged[f'team{team_num}_{col_null_match_identifier}'].isna() == True]\n",
    "        df_merged = df_merged[df_merged[f'team{team_num}_{col_null_match_identifier}'].isna() == False]\n",
    "        \n",
    "        print(f'Original Team {team_num} Merge:', len(df), 'total rows.')\n",
    "        print('Matched During Iteration:', len(df_merged)) \n",
    "        print('Unmatched Rows Remaining:', len(df_not_merged), '\\n') \n",
    "        \n",
    "        # Remove Columns That Didn't Merge Properly Based On Num of Columns\n",
    "        # Reduce To Team and Year, Along with Alternate Spellings\n",
    "        neg_col_count_df_merge_onto = df_merge_onto.shape[1] * -1\n",
    "        df_not_merged = df_not_merged.iloc[:, :neg_col_count_df_merge_onto]\n",
    "        \n",
    "        # Loop Through Columnns To Fix The Merge\n",
    "        print(f\"Correcting Team {team_num} Merge ...\\n\")\n",
    "        merge_complete, i = False, 1\n",
    "        while merge_complete == False:\n",
    "            \n",
    "            # Perform Loop Everytime More Unmatched Columns Are Found\n",
    "            team_season_loop = pd.merge(df_not_merged, df_merge_onto, how = 'left', left_on = [f'team{team_num}_name_spelling_{i}', 'season'], right_on = [f'team{team_num}_team', f'team{team_num}_year'])\n",
    "            print(f'Team {team_num} Season Loop {i}:', len(team_season_loop), 'total rows.')\n",
    "            \n",
    "            # Split Up The Matched and Unmatched\n",
    "            matched_df = team_season_loop[team_season_loop[f'team{team_num}_{col_null_match_identifier}'].isna() == False]\n",
    "            print('Matched During Iteration:', len(matched_df)) \n",
    "            unmatched_df = team_season_loop[team_season_loop[f'team{team_num}_{col_null_match_identifier}'].isna() == True]\n",
    "            print('Unmatched Rows Remaining:', len(unmatched_df), '\\n') \n",
    "            \n",
    "            # For The DataFrames With Data In The Column From Second DF, Add To team_season\n",
    "            if len(matched_df) > 0:\n",
    "                df_merged = pd.concat([df_merged, matched_df])\n",
    "            # If There Are Still Null Rows, Throw Those Back In The Loop For The Next Iteration\n",
    "            if len(unmatched_df) > 0:\n",
    "                df_not_merged = unmatched_df.iloc[:, :neg_col_count_df_merge_onto]\n",
    "            # If There Aren't Any Null Rows Left, End The Loop\n",
    "            else:\n",
    "                print(f'Success! Team {team_num} Merge Completed Early!\\n')\n",
    "                merge_complete = True\n",
    "            if i == 11:\n",
    "                merge_complete = True \n",
    "            i += 1\n",
    "   \n",
    "        # Concat Team 1 or 2 Onto Full DataFrame\n",
    "        if team_num == 2:\n",
    "            spellings = []\n",
    "            for col in df_merged.columns:\n",
    "                if 'team2_name_spelling' not in col:\n",
    "                    spellings.append(col)\n",
    "                \n",
    "            df_both_teams = pd.merge(df_both_teams, df_merged[spellings], how = 'left', on = [f'team2_teamname', 'season'])\n",
    "        else:\n",
    "            df_both_teams = pd.concat([df_merged, df_not_merged])\n",
    "    \n",
    "    # Inspect Final Results\n",
    "    print(\"Filter Views of Resulting DataFrame -------------------------\\n\")\n",
    "    for team_num in range(1, 3):\n",
    "        print(f'Team{team_num}:')\n",
    "        if filter_df_merge_onto_year != None:\n",
    "            # Gather Data About Merge Post Cutoff\n",
    "            post_cutoff_rows = df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == False) & (df_both_teams['season'] >= filter_df_merge_onto_year)].shape[0]\n",
    "            post_cutoff_rows_na = df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == True) & (df_both_teams['season'] >= filter_df_merge_onto_year)].shape[0]\n",
    "            \n",
    "            if post_cutoff_rows_na > 0:\n",
    "                print(f'Oh No! There were {post_cutoff_rows} matches and {post_cutoff_rows_na} post {filter_df_merge_onto_year} null games.')\n",
    "                \n",
    "                # # Get Teamnames That Dont Merge\n",
    "                # if pd.read_csv('../data/sample_spell.csv').shape[0] == pd.merge(pd.read_csv('../data/mdcm/team_spellings.csv'), \n",
    "                # pd.read_csv('../data/sample_spell.csv'), how = 'inner', left_on = 'name_spelling', right_on = 'team2_teamname').shape[0]:\n",
    "                #         print(\"Despite all the mismatches, none of them were in the merged onto Dataframe.\")\n",
    "                # else:\n",
    "                #     print(\"Here are the distinct team names from the 'df' dataframe that weren't merged properly:\")\n",
    "                #     print(df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == True) & (df_both_teams['season'] >= filter_df_merge_onto_year)][f'team{team_num}_teamname'].drop_duplicates().sort_values())\n",
    "            else:\n",
    "                print(f'Great! No Null Rows Post {filter_df_merge_onto_year}')\n",
    "     \n",
    "            # Gather Data About Merge Pre Cutoff\n",
    "            pre_cutoff_rows = df_both_teams[(df_both_teams[f'team{team_num}_{col_null_match_identifier}'].isna() == False) & (df_both_teams['season'] < filter_df_merge_onto_year)].shape[0]\n",
    "            if pre_cutoff_rows == 0:\n",
    "                print(f'Great! No Matched Rows Pre {filter_df_merge_onto_year}\\n')\n",
    "                                \n",
    "    # Concat Pre and Post Cutoff If Exists\n",
    "    if filter_df_merge_onto_year != None:\n",
    "        df_both_teams = pd.concat([df_both_teams, df_pre_cutoff], ignore_index=True)    \n",
    "    \n",
    "    return df_both_teams.drop(['team1_team','team1_year', 'team2_team', 'team2_year'], axis = 1)\n",
    "\n",
    "# Ammend List To Remove Duplicate Columns And Retain One Set \n",
    "def drop_dup_columns(df: pd.DataFrame, dup_cols_keep: list[str]):\n",
    "    same_data_columns = []\n",
    "    for i in range(df.shape[1] - 1):\n",
    "        for j in range(i + 1, df.shape[1]):\n",
    "            col1, col2 = df.columns[i], df.columns[j]\n",
    "            if df[col1].equals(df[col2]):\n",
    "                same_data_columns.append((col1, col2))\n",
    "    if not same_data_columns:\n",
    "        print(\"No columns have the same data.\")\n",
    "    else:\n",
    "        for col_pair in same_data_columns:\n",
    "            if col_pair not in dup_cols_keep:\n",
    "                df.drop(columns = col_pair[0], axis = 1, inplace = True)\n",
    "                df.rename(columns = {col_pair[1]: col_pair[1].replace('_away', '')}, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Round Column\n",
    "mdcm['round'] = mdcm['slot'].str.extract(r'(\\d+)')\n",
    "mdcm['round'] = pd.to_numeric(mdcm['round'], errors='coerce')\n",
    "\n",
    "# Adjust Team Spellings\n",
    "team_spellings = team_spellings.pivot_table(index='team_id', columns=team_spellings.groupby('team_id').cumcount(), values='name_spelling', aggfunc='first')\n",
    "team_spellings.columns = [f'name_spelling_{i + 1}' for i in range(team_spellings.shape[1])]\n",
    "team_spellings.reset_index(inplace=True)\n",
    "\n",
    "# Merge Team Spellings\n",
    "team_spellings_t1 = team_spellings.add_prefix('team1_')\n",
    "mdcm = pd.merge(mdcm, team_spellings_t1, how = 'inner', left_on = ['team1_id'], right_on = ['team1_team_id'])\n",
    "team_spellings_t2 = team_spellings.add_prefix('team2_')\n",
    "mdcm = pd.merge(mdcm, team_spellings_t2, how = 'inner', left_on = ['team2_id'], right_on = ['team2_team_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 129)\n",
      "MDCM and Selection Sunday (2008 - 2024) -----------------------\n",
      "\n",
      "Column Null Match Identifier: resume \n",
      "\n",
      "Team 1 Merge ...\n",
      "\n",
      "Original Team 1 Merge: 996 total rows.\n",
      "Matched During Iteration: 782\n",
      "Unmatched Rows Remaining: 214 \n",
      "\n",
      "Correcting Team 1 Merge ...\n",
      "\n",
      "Team 1 Season Loop 1: 214 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 214 \n",
      "\n",
      "Team 1 Season Loop 2: 214 total rows.\n",
      "Matched During Iteration: 9\n",
      "Unmatched Rows Remaining: 205 \n",
      "\n",
      "Team 1 Season Loop 3: 205 total rows.\n",
      "Matched During Iteration: 101\n",
      "Unmatched Rows Remaining: 104 \n",
      "\n",
      "Team 1 Season Loop 4: 104 total rows.\n",
      "Matched During Iteration: 37\n",
      "Unmatched Rows Remaining: 67 \n",
      "\n",
      "Team 1 Season Loop 5: 67 total rows.\n",
      "Matched During Iteration: 6\n",
      "Unmatched Rows Remaining: 61 \n",
      "\n",
      "Team 1 Season Loop 6: 61 total rows.\n",
      "Matched During Iteration: 2\n",
      "Unmatched Rows Remaining: 59 \n",
      "\n",
      "Team 1 Season Loop 7: 59 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 59 \n",
      "\n",
      "Team 1 Season Loop 8: 59 total rows.\n",
      "Matched During Iteration: 1\n",
      "Unmatched Rows Remaining: 58 \n",
      "\n",
      "Team 1 Season Loop 9: 58 total rows.\n",
      "Matched During Iteration: 6\n",
      "Unmatched Rows Remaining: 52 \n",
      "\n",
      "Team 1 Season Loop 10: 52 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 52 \n",
      "\n",
      "Team 1 Season Loop 11: 52 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 52 \n",
      "\n",
      "Team 2 Merge ...\n",
      "\n",
      "Original Team 2 Merge: 995 total rows.\n",
      "Matched During Iteration: 606\n",
      "Unmatched Rows Remaining: 389 \n",
      "\n",
      "Correcting Team 2 Merge ...\n",
      "\n",
      "Team 2 Season Loop 1: 389 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 389 \n",
      "\n",
      "Team 2 Season Loop 2: 389 total rows.\n",
      "Matched During Iteration: 21\n",
      "Unmatched Rows Remaining: 368 \n",
      "\n",
      "Team 2 Season Loop 3: 368 total rows.\n",
      "Matched During Iteration: 112\n",
      "Unmatched Rows Remaining: 256 \n",
      "\n",
      "Team 2 Season Loop 4: 256 total rows.\n",
      "Matched During Iteration: 37\n",
      "Unmatched Rows Remaining: 219 \n",
      "\n",
      "Team 2 Season Loop 5: 219 total rows.\n",
      "Matched During Iteration: 8\n",
      "Unmatched Rows Remaining: 211 \n",
      "\n",
      "Team 2 Season Loop 6: 211 total rows.\n",
      "Matched During Iteration: 5\n",
      "Unmatched Rows Remaining: 206 \n",
      "\n",
      "Team 2 Season Loop 7: 206 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 206 \n",
      "\n",
      "Team 2 Season Loop 8: 206 total rows.\n",
      "Matched During Iteration: 3\n",
      "Unmatched Rows Remaining: 203 \n",
      "\n",
      "Team 2 Season Loop 9: 203 total rows.\n",
      "Matched During Iteration: 8\n",
      "Unmatched Rows Remaining: 195 \n",
      "\n",
      "Team 2 Season Loop 10: 195 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 195 \n",
      "\n",
      "Team 2 Season Loop 11: 195 total rows.\n",
      "Matched During Iteration: 0\n",
      "Unmatched Rows Remaining: 195 \n",
      "\n",
      "Filter Views of Resulting DataFrame -------------------------\n",
      "\n",
      "Team1:\n",
      "Oh No! There were 944 matches and 52 post 2008 null games.\n",
      "Great! No Matched Rows Pre 2008\n",
      "\n",
      "Team2:\n",
      "Oh No! There were 801 matches and 195 post 2008 null games.\n",
      "Great! No Matched Rows Pre 2008\n",
      "\n",
      "(1380, 151)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Temp\\ipykernel_10500\\1399182595.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'team{team_num}_teamname'] = df[f'team{team_num}_teamname'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Merge MDCM and Selection Sunday (2008-2024)\n",
    "\n",
    "print(mdcm.shape)\n",
    "selection_sunday_resume = selection_sunday_resume[selection_sunday_resume['year'] != 'Year']\n",
    "selection_sunday_resume['year'] = selection_sunday_resume['year'].astype(int)\n",
    "selection_sunday_resume.drop(columns = ['net', 'seed'], axis = 1, inplace = True)\n",
    "selection_sunday_resume.rename(columns={'score': 'team_score'}, inplace=True)\n",
    "df = merge_team_season(mdcm, selection_sunday_resume, filter_df_merge_onto_year = 2008, title = 'MDCM and Selection Sunday (2008 - 2024)')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944              lehigh\n",
       "945              mercer\n",
       "946                 uab\n",
       "947          st peter's\n",
       "948         tx southern\n",
       "949           albany ny\n",
       "950       james madison\n",
       "951             radford\n",
       "952         f dickinson\n",
       "953        cal poly slo\n",
       "955           princeton\n",
       "958        oral roberts\n",
       "959           san diego\n",
       "960      ark pine bluff\n",
       "961             harvard\n",
       "963            richmond\n",
       "964         morehead st\n",
       "965      ut san antonio\n",
       "966          holy cross\n",
       "967       fl gulf coast\n",
       "968            marshall\n",
       "969           oregon st\n",
       "972         n dakota st\n",
       "973            uc davis\n",
       "974       unc asheville\n",
       "977          w kentucky\n",
       "979                ohio\n",
       "981              furman\n",
       "983                umbc\n",
       "984           wright st\n",
       "986      tam c. christi\n",
       "988          norfolk st\n",
       "989             hampton\n",
       "990              nc a&t\n",
       "992             vermont\n",
       "993        mt st mary's\n",
       "995       robert morris\n",
       "996              Kansas\n",
       "997         Michigan St\n",
       "998             Indiana\n",
       "999         Connecticut\n",
       "1000                LSU\n",
       "1001    VA Commonwealth\n",
       "1002         Texas Tech\n",
       "1003           Missouri\n",
       "1004            Florida\n",
       "1008            Alabama\n",
       "1009              Tulsa\n",
       "1012         Louisville\n",
       "1013                UAB\n",
       "1014     North Carolina\n",
       "1015           Illinois\n",
       "1019           Kentucky\n",
       "1022            Arizona\n",
       "1023         Pittsburgh\n",
       "1025           Maryland\n",
       "1026               UNLV\n",
       "1029              Texas\n",
       "1030           NC State\n",
       "1031             Nevada\n",
       "1032       George Mason\n",
       "1035               Duke\n",
       "1036         Notre Dame\n",
       "1037         Washington\n",
       "1038      Virginia Tech\n",
       "1041            Georgia\n",
       "1045     UNC Wilmington\n",
       "1046                USC\n",
       "1047           Bucknell\n",
       "1048         Vanderbilt\n",
       "1050             Xavier\n",
       "1051             Butler\n",
       "1052          Texas A&M\n",
       "1053             Purdue\n",
       "1054               UCLA\n",
       "1060            Wyoming\n",
       "1063           Syracuse\n",
       "1064               Utah\n",
       "1065       WI Milwaukee\n",
       "1070      West Virginia\n",
       "1071         C Michigan\n",
       "1074            Pacific\n",
       "1075            Gonzaga\n",
       "1081           Winthrop\n",
       "1083            Vermont\n",
       "1085      UNC Asheville\n",
       "1086           Oklahoma\n",
       "1090          Marquette\n",
       "1099         Georgetown\n",
       "1101        Oklahoma St\n",
       "1104         S Illinois\n",
       "1108     Mississippi St\n",
       "1115          Villanova\n",
       "1119         Seton Hall\n",
       "1124     Boston College\n",
       "1136             Oregon\n",
       "1137            Ohio St\n",
       "1142         Arizona St\n",
       "1145             DePaul\n",
       "1146        Florida A&M\n",
       "1147         Cincinnati\n",
       "1148          Wisconsin\n",
       "1154         California\n",
       "1160           Stanford\n",
       "1176         Wichita St\n",
       "1177            Memphis\n",
       "1180          Tennessee\n",
       "1186          Creighton\n",
       "1187          Manhattan\n",
       "1192       Georgia Tech\n",
       "1199               Kent\n",
       "1201            Bradley\n",
       "1207    Northwestern LA\n",
       "1223     St Joseph's PA\n",
       "1226      Washington St\n",
       "1259        Monmouth NJ\n",
       "1261           Virginia\n",
       "1270       G Washington\n",
       "1295            Iowa St\n",
       "1299            Montana\n",
       "1313        Wake Forest\n",
       "1322             Auburn\n",
       "1359            Niagara\n",
       "1375              Siena\n",
       "1379            Oakland\n",
       "Name: team1_teamname, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['team1_resume'].isna() == True]['team1_teamname'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge MDCM and Kenpom Barttovik (2008-2024)\n",
    "kenpom_barttovik.columns = kenpom_barttovik.columns.str.lower()\n",
    "kenpom_barttovik = kenpom_barttovik[['year', 'team', 'barthag', 'avg hgt', 'eff hgt', 'exp', 'talent', 'pppo', 'pppd', 'elite sos']]\n",
    "df = merge_team_season(df, kenpom_barttovik, filter_df_merge_onto_year = 2008, title = 'MDCM and Kenpom Barttovik (2008 - 2024)')\n",
    "print(df.shape)\n",
    "\n",
    "# Merge Home Team Barttovik Data (2008-2024)\n",
    "barttovik_home.columns = barttovik_home.columns.str.lower()\n",
    "barttovik_home.drop(columns = ['seed', 'round', 'wab'], axis = 1, inplace = True)\n",
    "barttovik_home.rename(columns={col: f'home_' + col for col in barttovik_home.columns[-1 * (barttovik_home.shape[1]):]}, inplace=True)\n",
    "barttovik_home = barttovik_home[['home_year','home_team', 'home_badj em', 'home_badj o', 'home_badj d', 'home_barthag', \n",
    "                                 'home_badj t', 'home_pppo', 'home_pppd','home_3pt%', 'home_ft%']]\n",
    "barttovik_home.rename(columns={f'home_team':'team', 'home_year':'year'}, inplace = True)\n",
    "df = merge_team_season(df, barttovik_home, filter_df_merge_onto_year = 2008, title = 'MDCM and Home Barttovic Data (2008 - 2024)')\n",
    "print(df.shape)\n",
    "\n",
    "# Merge Away Team Barttovik Data (2008-2024)\n",
    "barttovik_away.columns = barttovik_away.columns.str.lower()\n",
    "barttovik_away.drop(columns = ['seed', 'round', 'wab'], axis = 1, inplace = True)\n",
    "barttovik_away.rename(columns={col: f'away_' + col for col in barttovik_away.columns[-1 * (barttovik_away.shape[1]):]}, inplace=True)\n",
    "barttovik_away = barttovik_away[['away_year','away_team', 'away_badj em', 'away_badj o', 'away_badj d', 'away_barthag', \n",
    "                                 'away_badj t', 'away_pppo', 'away_pppd','away_3pt%', 'away_ft%']]\n",
    "barttovik_away.rename(columns={f'away_team':'team', 'away_year':'year'}, inplace = True)\n",
    "df = merge_team_season(df, barttovik_away, filter_df_merge_onto_year = 2008, title = 'MDCM and Away Barttovic Data (2008 - 2024)')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shooting Splits (2010-2024)\n",
    "shooting_splits.columns = shooting_splits.columns.str.lower()\n",
    "shooting_splits = shooting_splits.drop(['conf'], axis=1, errors='ignore')\n",
    "df = merge_team_season(df, shooting_splits, filter_df_merge_onto_year = 2010, title = 'MDCM and Kenpom Barttovik (2013 - 2024)')\n",
    "\n",
    "# Remove Rank From DataFrame\n",
    "df = df.loc[:, ~df.columns.str.contains('rank', case=False)].dropna(axis=1, how='all')\n",
    "df = df.loc[:, ~df.columns.str.contains('name_spelling')]\n",
    "df.to_csv(\"../data/pipeline/merged_team_season.csv\", index = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 151)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge MDCM and Kenpom Barttovik (2008-2024)\n",
    "kenpom_barttovik.columns = kenpom_barttovik.columns.str.lower()\n",
    "kenpom_barttovik = kenpom_barttovik[['year', 'team', 'barthag', 'avg hgt', 'eff hgt', 'exp', 'talent', 'pppo', 'pppd', 'elite sos']]\n",
    "df = merge_team_season(df, kenpom_barttovik, filter_df_merge_onto_year = 2008, title = 'MDCM and Kenpom Barttovik (2008 - 2024)')\n",
    "\n",
    "# Merge Home Team Barttovik Data (2008-2024)\n",
    "barttovik_home.columns = barttovik_home.columns.str.lower()\n",
    "barttovik_home.drop(columns = ['seed', 'round', 'wab'], axis = 1, inplace = True)\n",
    "barttovik_home.rename(columns={col: f'home_' + col for col in barttovik_home.columns[-1 * (barttovik_home.shape[1]):]}, inplace=True)\n",
    "barttovik_home = barttovik_home[['home_year','home_team', 'home_badj em', 'home_badj o', 'home_badj d', 'home_barthag', \n",
    "                                 'home_badj t', 'home_pppo', 'home_pppd','home_3pt%', 'home_ft%']]\n",
    "barttovik_home.rename(columns={f'home_team':'team', 'home_year':'year'}, inplace = True)\n",
    "df = merge_team_season(df, barttovik_home, filter_df_merge_onto_year = 2008, title = 'MDCM and Home Barttovic Data (2008 - 2024)')\n",
    "\n",
    "# Merge Away Team Barttovik Data (2008-2024)\n",
    "barttovik_away.columns = barttovik_away.columns.str.lower()\n",
    "barttovik_away.drop(columns = ['seed', 'round', 'wab'], axis = 1, inplace = True)\n",
    "barttovik_away.rename(columns={col: f'away_' + col for col in barttovik_away.columns[-1 * (barttovik_away.shape[1]):]}, inplace=True)\n",
    "barttovik_away = barttovik_away[['away_year','away_team', 'away_badj em', 'away_badj o', 'away_badj d', 'away_barthag', \n",
    "                                 'away_badj t', 'away_pppo', 'away_pppd','away_3pt%', 'away_ft%']]\n",
    "barttovik_away.rename(columns={f'away_team':'team', 'away_year':'year'}, inplace = True)\n",
    "df = merge_team_season(df, barttovik_away, filter_df_merge_onto_year = 2008, title = 'MDCM and Away Barttovic Data (2008 - 2024)')\n",
    "\n",
    "# Shooting Splits (2010-2024)\n",
    "shooting_splits.columns = shooting_splits.columns.str.lower()\n",
    "shooting_splits = shooting_splits.drop(['conf'], axis=1, errors='ignore')\n",
    "df = merge_team_season(df, shooting_splits, filter_df_merge_onto_year = 2010, title = 'MDCM and Kenpom Barttovik (2013 - 2024)')\n",
    "\n",
    "# Remove Rank From DataFrame\n",
    "df = df.loc[:, ~df.columns.str.contains('rank', case=False)].dropna(axis=1, how='all')\n",
    "df = df.loc[:, ~df.columns.str.contains('name_spelling')]\n",
    "df.to_csv(\"../data/pipeline/merged_team_season.csv\", index = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>first round</th>\n",
       "      <th>second round</th>\n",
       "      <th>sweet 16</th>\n",
       "      <th>elite 8</th>\n",
       "      <th>final 4</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  first round  second round  sweet 16  elite 8  final 4  total\n",
       "0  2023            5             4         3        2        0     14\n",
       "1  2022            7             5         4        0        1     17\n",
       "2  2021            9             6         2        1        0     18\n",
       "3  2019            8             0         1        2        0     11\n",
       "4  2018            6             5         3        1        0     15"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upset Frequencies (2023-2008)\n",
    "upset_counts = pd.read_csv('../data/kaggle/march_madness_data/upset_counts.csv')\n",
    "upset_counts.columns = upset_counts.columns.str.lower()\n",
    "upset_counts.head()\n",
    "\n",
    "for row in upset_counts.shape[0]:\n",
    "    upset_counts_no_current_year = upset_counts[upset_counts['year'] != row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre and During NCAA Tourney Split of Data, Include Rolling Averages For Team Performance (Values as of Date)\n",
    "\n",
    "# Import Team Ratings By Day (2015-2019)\n",
    "team_ratings = pd.read_csv('../data/cbbdata/team/team_ratings.csv').query('year != 2020')\n",
    "team_ratings['date']= pd.to_datetime(team_ratings['date'])\n",
    "\n",
    "# Split Daily Team Ranknings By Before/After Selection Sunday\n",
    "ss_dict = {2024: \"2024-3-17\", 2023: \"2023-3-12\", 2022: \"2022-3-13\", \n",
    "           2021: \"2021-3-14\", 2019: \"2019-3-17\", 2018: \"2018-3-11\", \n",
    "           2017: \"2017-3-12\", 2016: \"2016-3-13\", 2015: \"2015-3-15\"}\n",
    "\n",
    "# Create A Pre and During NCAA Tournament Day By Day Ratings\n",
    "team_rating_pre_ncaa = pd.DataFrame(columns = team_ratings.columns)\n",
    "team_rating_ncaa = pd.DataFrame(columns = team_ratings.columns)\n",
    "for year, ss_date in ss_dict.items():\n",
    "    team_rating_pre_ncaa = pd.concat([team_rating_pre_ncaa, team_ratings[(team_ratings['year'] == year) & (team_ratings['date'] < ss_date)]])    \n",
    "    team_rating_ncaa = pd.concat([team_rating_ncaa, team_ratings[(team_ratings['year'] == year) & (team_ratings['date'] > ss_date)]])\n",
    "    \n",
    "# Look At Team Rating By Day and Calculate Rolling Adj Offensive Rank\n",
    "team_rating_pre_ncaa['rolling_avg_adj_o_rk'] = team_rating_pre_ncaa.groupby(['team', 'year'])['adj_o'].transform(lambda x: x.rolling(window=3).mean())\n",
    "team_rating_pre_ncaa[(team_rating_pre_ncaa['team'] == 'Kentucky') & (team_rating_pre_ncaa['year'] == 2015)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Temp\\ipykernel_24000\\3081602681.py:1: DtypeWarning: Columns (25,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  game_factors = pd.read_csv('../data/cbbdata/game/game_factors.csv').query('year != 2020')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>team</th>\n",
       "      <th>conf</th>\n",
       "      <th>opp</th>\n",
       "      <th>opp_conf</th>\n",
       "      <th>loc</th>\n",
       "      <th>result</th>\n",
       "      <th>pts_scored</th>\n",
       "      <th>pts_allowed</th>\n",
       "      <th>adjo_game</th>\n",
       "      <th>adjd_game</th>\n",
       "      <th>off_ppp</th>\n",
       "      <th>off_efg</th>\n",
       "      <th>off_to</th>\n",
       "      <th>off_or</th>\n",
       "      <th>off_ftr</th>\n",
       "      <th>def_ppp</th>\n",
       "      <th>def_efg</th>\n",
       "      <th>def_to</th>\n",
       "      <th>def_or</th>\n",
       "      <th>def_ftr</th>\n",
       "      <th>game_score</th>\n",
       "      <th>season</th>\n",
       "      <th>tempo</th>\n",
       "      <th>game_id</th>\n",
       "      <th>coach</th>\n",
       "      <th>opp_coach</th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>avg_marg</th>\n",
       "      <th>rank</th>\n",
       "      <th>record</th>\n",
       "      <th>barthag</th>\n",
       "      <th>adjo_season_date</th>\n",
       "      <th>adj_o_rk</th>\n",
       "      <th>adjd_season_date</th>\n",
       "      <th>adj_d_rk</th>\n",
       "      <th>adj_tempo</th>\n",
       "      <th>adj_tempo_rk</th>\n",
       "      <th>proj_record</th>\n",
       "      <th>proj_conf_record</th>\n",
       "      <th>wab</th>\n",
       "      <th>wab_rk</th>\n",
       "      <th>rec</th>\n",
       "      <th>proj_rec</th>\n",
       "      <th>proj_conf_rec</th>\n",
       "      <th>cur_rk</th>\n",
       "      <th>change</th>\n",
       "      <th>rolling_avg_adj_o_rk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>conf_t</td>\n",
       "      <td>Akron</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>MAC</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>91.4</td>\n",
       "      <td>96.7</td>\n",
       "      <td>91.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>96.4</td>\n",
       "      <td>45.9</td>\n",
       "      <td>22.6</td>\n",
       "      <td>34.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>34.2</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>BuffaloAkron3-12</td>\n",
       "      <td>Keith Dambrot</td>\n",
       "      <td>Nate Oats</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>25-8</td>\n",
       "      <td>0.720127</td>\n",
       "      <td>109.546395</td>\n",
       "      <td>81</td>\n",
       "      <td>100.903669</td>\n",
       "      <td>126</td>\n",
       "      <td>68.500901</td>\n",
       "      <td>202</td>\n",
       "      <td>25.3-8.7</td>\n",
       "      <td>13-5</td>\n",
       "      <td>-1.092046</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.961430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>conf_t</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Akron</td>\n",
       "      <td>MAC</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>101.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>45.9</td>\n",
       "      <td>22.6</td>\n",
       "      <td>34.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>91.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>87.1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>BuffaloAkron3-12</td>\n",
       "      <td>Nate Oats</td>\n",
       "      <td>Keith Dambrot</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139</td>\n",
       "      <td>19-14</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>104.973415</td>\n",
       "      <td>153</td>\n",
       "      <td>102.514686</td>\n",
       "      <td>151</td>\n",
       "      <td>72.986535</td>\n",
       "      <td>28</td>\n",
       "      <td>19.1-14.9</td>\n",
       "      <td>10-8</td>\n",
       "      <td>-5.527029</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.926304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>conf_t</td>\n",
       "      <td>Cal St. Bakersfield</td>\n",
       "      <td>WAC</td>\n",
       "      <td>New Mexico St.</td>\n",
       "      <td>WAC</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>106.8</td>\n",
       "      <td>90.5</td>\n",
       "      <td>96.1</td>\n",
       "      <td>47.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>43.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>35.1</td>\n",
       "      <td>45.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>59.3</td>\n",
       "      <td>Cal St. BakersfieldNew Mexico St.3-12</td>\n",
       "      <td>Rod Barnes</td>\n",
       "      <td>Marvin Menzies</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>21-8</td>\n",
       "      <td>0.714282</td>\n",
       "      <td>102.855153</td>\n",
       "      <td>181</td>\n",
       "      <td>94.978036</td>\n",
       "      <td>29</td>\n",
       "      <td>68.587124</td>\n",
       "      <td>196</td>\n",
       "      <td>21.2-8.8</td>\n",
       "      <td>11-3</td>\n",
       "      <td>-3.333534</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.721049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>conf_t</td>\n",
       "      <td>New Mexico St.</td>\n",
       "      <td>WAC</td>\n",
       "      <td>Cal St. Bakersfield</td>\n",
       "      <td>WAC</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "      <td>95.8</td>\n",
       "      <td>98.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>43.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>35.1</td>\n",
       "      <td>45.8</td>\n",
       "      <td>96.1</td>\n",
       "      <td>47.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.1</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>59.3</td>\n",
       "      <td>Cal St. BakersfieldNew Mexico St.3-12</td>\n",
       "      <td>Marvin Menzies</td>\n",
       "      <td>Rod Barnes</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>21-10</td>\n",
       "      <td>0.651555</td>\n",
       "      <td>101.791294</td>\n",
       "      <td>203</td>\n",
       "      <td>96.399421</td>\n",
       "      <td>46</td>\n",
       "      <td>66.535250</td>\n",
       "      <td>299</td>\n",
       "      <td>21.1-10.9</td>\n",
       "      <td>13-1</td>\n",
       "      <td>-3.889725</td>\n",
       "      <td>108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.668366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>conf_t</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Amer</td>\n",
       "      <td>Temple</td>\n",
       "      <td>Amer</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>122.3</td>\n",
       "      <td>93.9</td>\n",
       "      <td>117.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>26.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>94.2</td>\n",
       "      <td>39.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>34.4</td>\n",
       "      <td>95.4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>65.8</td>\n",
       "      <td>ConnecticutTemple3-12</td>\n",
       "      <td>Kevin Ollie</td>\n",
       "      <td>Fran Dunphy</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>23-10</td>\n",
       "      <td>0.875603</td>\n",
       "      <td>110.127964</td>\n",
       "      <td>70</td>\n",
       "      <td>92.939894</td>\n",
       "      <td>14</td>\n",
       "      <td>67.075610</td>\n",
       "      <td>274</td>\n",
       "      <td>24.5-11.5</td>\n",
       "      <td>11-7</td>\n",
       "      <td>1.166640</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.501952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    type                 team  conf                  opp opp_conf  \\\n",
       "0 2016-03-12  conf_t                Akron   MAC              Buffalo      MAC   \n",
       "1 2016-03-12  conf_t              Buffalo   MAC                Akron      MAC   \n",
       "2 2016-03-12  conf_t  Cal St. Bakersfield   WAC       New Mexico St.      WAC   \n",
       "3 2016-03-12  conf_t       New Mexico St.   WAC  Cal St. Bakersfield      WAC   \n",
       "4 2016-03-12  conf_t          Connecticut  Amer               Temple     Amer   \n",
       "\n",
       "  loc result  pts_scored  pts_allowed  adjo_game  adjd_game  off_ppp  off_efg  \\\n",
       "0   N      L          61           64       91.4       96.7     91.9     50.0   \n",
       "1   N      W          64           61      101.5       86.0     96.4     45.9   \n",
       "2   N      W          57           54      106.8       90.5     96.1     47.2   \n",
       "3   N      L          54           57       95.8       98.9     91.0     43.8   \n",
       "4   N      W          77           62      122.3       93.9    117.0     58.0   \n",
       "\n",
       "   off_to  off_or  off_ftr  def_ppp  def_efg  def_to  def_or  def_ftr  \\\n",
       "0    18.1    16.7      3.4     96.4     45.9    22.6    34.2     13.1   \n",
       "1    22.6    34.2     13.1     91.9     50.0    18.1    16.7      3.4   \n",
       "2    18.5    33.3     24.1     91.0     43.8    23.6    35.1     45.8   \n",
       "3    23.6    35.1     45.8     96.1     47.2    18.5    33.3     24.1   \n",
       "4    13.7    26.9     26.8     94.2     39.1    12.2    35.6     34.4   \n",
       "\n",
       "   game_score  season  tempo                                game_id  \\\n",
       "0        34.2  2016.0   66.4                       BuffaloAkron3-12   \n",
       "1        87.1  2016.0   66.4                       BuffaloAkron3-12   \n",
       "2        87.0  2016.0   59.3  Cal St. BakersfieldNew Mexico St.3-12   \n",
       "3        40.9  2016.0   59.3  Cal St. BakersfieldNew Mexico St.3-12   \n",
       "4        95.4  2016.0   65.8                  ConnecticutTemple3-12   \n",
       "\n",
       "            coach       opp_coach  year location  avg_marg rank record  \\\n",
       "0   Keith Dambrot       Nate Oats  2016      NaN       NaN   92   25-8   \n",
       "1       Nate Oats   Keith Dambrot  2016      NaN       NaN  139  19-14   \n",
       "2      Rod Barnes  Marvin Menzies  2016      NaN       NaN   94   21-8   \n",
       "3  Marvin Menzies      Rod Barnes  2016      NaN       NaN  112  21-10   \n",
       "4     Kevin Ollie     Fran Dunphy  2016      NaN       NaN   33  23-10   \n",
       "\n",
       "    barthag  adjo_season_date adj_o_rk  adjd_season_date adj_d_rk  adj_tempo  \\\n",
       "0  0.720127        109.546395       81        100.903669      126  68.500901   \n",
       "1  0.567722        104.973415      153        102.514686      151  72.986535   \n",
       "2  0.714282        102.855153      181         94.978036       29  68.587124   \n",
       "3  0.651555        101.791294      203         96.399421       46  66.535250   \n",
       "4  0.875603        110.127964       70         92.939894       14  67.075610   \n",
       "\n",
       "  adj_tempo_rk proj_record proj_conf_record       wab wab_rk  rec  proj_rec  \\\n",
       "0          202    25.3-8.7             13-5 -1.092046     79  NaN       NaN   \n",
       "1           28   19.1-14.9             10-8 -5.527029    130  NaN       NaN   \n",
       "2          196    21.2-8.8             11-3 -3.333534     98  NaN       NaN   \n",
       "3          299   21.1-10.9             13-1 -3.889725    108  NaN       NaN   \n",
       "4          274   24.5-11.5             11-7  1.166640     39  NaN       NaN   \n",
       "\n",
       "   proj_conf_rec  cur_rk  change  rolling_avg_adj_o_rk  \n",
       "0            NaN     0.0     0.0            109.961430  \n",
       "1            NaN     0.0     0.0            104.926304  \n",
       "2            NaN     0.0     0.0            102.721049  \n",
       "3            NaN     0.0     0.0            101.668366  \n",
       "4            NaN     0.0     0.0            109.501952  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_factors = pd.read_csv('../data/cbbdata/game/game_factors.csv').query('year != 2020')\n",
    "\n",
    "game_factors['date']= pd.to_datetime(game_factors['date'])\n",
    "team_rating_pre_ncaa['date']= pd.to_datetime(team_rating_pre_ncaa['date'])\n",
    "\n",
    "test = pd.merge(game_factors[game_factors['year'] > 2015], team_rating_pre_ncaa.drop(columns = ['conf', 'year']), how = 'inner', on = ['team', 'date'])\n",
    "test = test.rename(columns = {'adj_o_x':'adjo_game', 'adj_d_x':'adjd_game','adj_o_y':'adjo_season_date', 'adj_d_y':'adjd_season_date'})\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
